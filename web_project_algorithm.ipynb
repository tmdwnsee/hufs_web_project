{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wjlt9s6_HEw",
        "outputId": "551c6e4f-98b1-4cb4-9f85-8c27572d4e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용자에게 추천하는 여행지 순서:\n",
            "['서울']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# 가상의 여행지 데이터 생성\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '경주', '제주', '강릉', '전주', '대구', '속초'],\n",
        "    '키워드': ['문화 역사 도시', '바다 해변 도시 번화가', '문화 역사 도시', '바다 자연 풍경', '자연 풍경 고즈넉한', '문화 역사 도시', '도시 번화가', '바다 해변 도시']\n",
        "})\n",
        "\n",
        "# 사용자 입력 키워드\n",
        "user_keywords = '바다 해변 도시 번화가'\n",
        "\n",
        "# TF-IDF 벡터화 => 검색과 문서 간의 일치도 평가를 위해 사용 되는 것으로 관련성에 따라 순위를 매기는데 사용 즉 클러스터링(유사한 성격 가진 개체 묶는 것)\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['키워드'])\n",
        "\n",
        "# 입력 키워드와 여행지 키워드 간의 코사인 유사도 계산\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_vectorizer.transform([user_keywords]))\n",
        "\n",
        "# 코사인 유사도를 기반으로 여행지 추천\n",
        "similarity_scores = list(enumerate(cosine_sim[0]))\n",
        "sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "recommended_destinations = [data['여행지'][i] for i, _ in sorted_scores]\n",
        "\n",
        "print(\"사용자에게 추천하는 여행지 순서:\")\n",
        "print(recommended_destinations)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qODf8Qi248gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z49VjDid_rvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 가상의 여행지 데이터\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '경주', '강릉'],\n",
        "    '평균 별점': [4.5, 4.2, 4.8, 4.0, 4.6]\n",
        "})\n",
        "\n",
        "# 사용자 리뷰 데이터 (가상 데이터)\n",
        "reviews = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '강릉'],\n",
        "    '사용자 리뷰': ['서울은 역사적인 장소가 많고 맛집도 많아서 좋았어요.', '부산의 바다 풍경이 아름답고 음식도 훌륭해요.',\n",
        "                 '제주는 자연 풍경이 멋지고 휴식하기 좋았습니다.', '강릉은 조용하고 아름다운 곳이에요.'],\n",
        "    '별점': [4.5, 4.2, 4.8, 4.6]\n",
        "})\n",
        "\n",
        "# 평가 데이터베이스 합치기\n",
        "merged_data = pd.merge(data, reviews, on='여행지')\n",
        "\n",
        "# 여행지를 별점을 기준으로 내림차순 정렬하여 순위 매기기\n",
        "sorted_data = merged_data.sort_values(by='평균 별점', ascending=False)\n",
        "\n",
        "# 순위를 새로운 열로 추가\n",
        "sorted_data['순위'] = range(1, len(sorted_data) + 1)\n",
        "\n",
        "# 인덱스를 제거하고 순위가 나타나도록 출력\n",
        "print(sorted_data[['순위', '여행지', '평균 별점']].to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NefFwo__Mfc",
        "outputId": "da71147d-986b-4c0b-afdf-19ee5c55c21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 순위 여행지  평균 별점\n",
            "  1  제주    4.8\n",
            "  2  강릉    4.6\n",
            "  3  서울    4.5\n",
            "  4  부산    4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 가상의 여행지 데이터\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '경주', '강릉'],\n",
        "    '평균 별점': [3.5, 2.2, 1.8, 5.0, 1.6]\n",
        "})\n",
        "\n",
        "# 사용자 리뷰 데이터 (가상 데이터)\n",
        "reviews = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '강릉'],\n",
        "    '사용자 리뷰': ['서울은 역사적인 장소가 많고 맛집도 많아서 좋았어요.', '부산의 바다 풍경이 아름답고 음식도 훌륭해요.',\n",
        "                 '제주는 자연 풍경이 멋지고 휴식하기 좋았습니다.', '강릉은 조용하고 아름다운 곳이에요.'],\n",
        "    '별점': [4.5, 4.2, 4.8, 4.6]\n",
        "})\n",
        "\n",
        "# 평가 데이터베이스 합치기\n",
        "merged_data = pd.merge(data, reviews, on='여행지')\n",
        "\n",
        "# 여행지를 별점을 기준으로 내림차순 정렬하여 순위 매기기\n",
        "sorted_data = merged_data.sort_values(by='평균 별점', ascending=False)\n",
        "\n",
        "# 순위를 새로운 열로 추가\n",
        "sorted_data['순위'] = range(1, len(sorted_data) + 1)\n",
        "\n",
        "# 상위 5개 행만 선택하여 출력\n",
        "top_5 = sorted_data[['순위', '여행지', '평균 별점']].head(5)\n",
        "print(top_5.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS-p-HiJ_NNO",
        "outputId": "c8a7abab-690e-4d10-a5a9-4e2ce1b40719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 순위 여행지  평균 별점\n",
            "  1  서울    3.5\n",
            "  2  부산    2.2\n",
            "  3  제주    1.8\n",
            "  4  강릉    1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# 여행지와 리뷰 데이터 생성\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '강릉', '경주'],\n",
        "    '평균 별점': [4.5, 4.2, 4.8, 4.6, 4.0]\n",
        "})\n",
        "\n",
        "reviews = pd.DataFrame({\n",
        "    '여행지': ['서울'] * 5 + ['부산'] * 5 + ['제주'] * 5 + ['강릉'] * 5 + ['경주'] * 5,\n",
        "    '해시태그': [\n",
        "        ##서울 해쉬태그\n",
        "        '#도시 #맛집 #역사',\n",
        "        '#부자 #도시 #맛집',\n",
        "        '#빌딩 #풍경 #번화',\n",
        "        '#번화 #아름다운',\n",
        "        '#도시 #문화',\n",
        "        ##부산 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#바다 #풍경 #도시',\n",
        "        '#번화 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##제주 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식 # 바다',\n",
        "        '#바다 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##강릉 해쉬태그\n",
        "        '#산 #맛집 #도시',\n",
        "        '#산 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식',\n",
        "        '#산 #아름다운',\n",
        "        '#산 #조용',\n",
        "        ##경주 해쉬태그\n",
        "        '#역사 #맛집 #휴식',\n",
        "        '#역사 #풍경 #맛집',\n",
        "        '#역사 #풍경 #휴식',\n",
        "        '#역사 #아름다운',\n",
        "        '#역사 #문화',\n",
        "    ],\n",
        "    '별점': [4.5, 4.8, 4.3, 4.6, 4.7,\n",
        "            4.2, 4.5, 4.4, 4.6, 4.3,\n",
        "            2.8, 3.0, 3.5, 4.0, 3.8,\n",
        "            4.6, 4.7, 4.5, 4.2, 4.4,\n",
        "            3.9, 4.1, 3.7, 4.0, 4.2]\n",
        "})\n",
        "\n",
        "# 사용자 입력 해시태그에 따라 관련 리뷰를 추천\n",
        "def get_recommendations_by_hashtags(input_hashtags, cosine_sim = cosine_sim):\n",
        "    # 입력된 해시태그를 벡터화\n",
        "    input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "\n",
        "    # 유사도에 따라 리뷰 정렬\n",
        "    related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "\n",
        "    # 상위 5개의 리뷰 추천\n",
        "    top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "\n",
        "    # 추천된 리뷰 중에서 각 도시가 몇 번 나왔는지 카운트\n",
        "    city_counts = top_reviews['여행지'].value_counts()\n",
        "\n",
        "    # 도시별 추천 순위 매기기\n",
        "    city_rankings = city_counts.reset_index()\n",
        "    city_rankings.columns = ['도시', '추천 횟수']\n",
        "    city_rankings['순위'] = city_rankings['추천 횟수'].rank(ascending=False, method='min')\n",
        "\n",
        "    # 가장 많이 추천된 상위 5개의 도시 추천\n",
        "    top_cities = city_rankings[city_rankings['순위'] <= 5]\n",
        "\n",
        "    # 각 도시에서 가장 많이 태그된 해시태그 가져오기\n",
        "    top_cities['대표 태그'] = top_cities['도시'].apply(\n",
        "        lambda city: reviews[reviews['여행지'] == city]['해시태그'].value_counts().idxmax()\n",
        "    )\n",
        "\n",
        "    return top_cities\n",
        "\n",
        "# 사용자 입력 해시태그\n",
        "input_hashtags = '도시'  # 사용자가 입력한 해시태그\n",
        "\n",
        "# 입력된 해시태그에 따라 관련 리뷰 추천 및 대표 태그 출력\n",
        "recommended_cities = get_recommendations_by_hashtags(input_hashtags)\n",
        "print(recommended_cities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10mVqvd4_OWw",
        "outputId": "dc5554c3-ecc8-476c-c049-293e81fa8485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도시  추천 횟수   순위        대표 태그\n",
            "0  부산      3  1.0  #바다 #맛집 #도시\n",
            "1  서울      2  2.0  #도시 #맛집 #역사\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# 여행지와 리뷰 데이터 생성\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '강릉', '경주'],\n",
        "    '평균 별점': [4.5, 4.2, 4.8, 4.6, 4.0]\n",
        "})\n",
        "\n",
        "reviews = pd.DataFrame({\n",
        "    '여행지': ['서울'] * 5 + ['부산'] * 5 + ['제주'] * 5 + ['강릉'] * 5 + ['경주'] * 5,\n",
        "    '해시태그': [\n",
        "        ##서울 해쉬태그\n",
        "        '#도시 #맛집 #역사',\n",
        "        '#부자 #도시 #맛집',\n",
        "        '#빌딩 #풍경 #번화',\n",
        "        '#번화 #아름다운',\n",
        "        '#도시 #문화',\n",
        "        ##부산 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#바다 #풍경 #도시',\n",
        "        '#번화 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##제주 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식 # 바다',\n",
        "        '#바다 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##강릉 해쉬태그\n",
        "        '#산 #맛집 #도시',\n",
        "        '#산 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식',\n",
        "        '#산 #아름다운',\n",
        "        '#산 #조용',\n",
        "        ##경주 해쉬태그\n",
        "        '#역사 #맛집 #휴식',\n",
        "        '#역사 #풍경 #맛집',\n",
        "        '#역사 #풍경 #휴식',\n",
        "        '#역사 #아름다운',\n",
        "        '#역사 #문화',\n",
        "    ],\n",
        "    '별점': [4.5, 4.8, 4.3, 4.6, 4.7,\n",
        "            4.2, 4.5, 4.4, 4.6, 4.3,\n",
        "            2.8, 3.0, 3.5, 4.0, 3.8,\n",
        "            4.6, 4.7, 4.5, 4.2, 4.4,\n",
        "            3.9, 4.1, 3.7, 4.0, 4.2]\n",
        "})\n",
        "\n",
        "# 사용 가능한 해시태그 목록\n",
        "available_hashtags = ['#도시', '#자연', '#역사', '#바다','#산', '#맛집','#풍경']\n",
        "\n",
        "# 사용자에게 입력 받기\n",
        "print(\"#도시 #자연 #역사 #바다 #산 #맛집 #풍경\")\n",
        "selected_hashtag = input(\"사용하려는 해시태그를 선택하세요: \")\n",
        "if selected_hashtag not in available_hashtags:\n",
        "    print(\"잘못된 해시태그입니다.\")\n",
        "else:\n",
        "    # 입력된 해시태그에 따라 관련 리뷰를 추천\n",
        "    def get_recommendations_by_hashtags(input_hashtags, cosine_sim=cosine_sim):\n",
        "        # 입력된 해시태그를 벡터화\n",
        "        input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "\n",
        "        # 코사인 유사도 계산\n",
        "        sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "\n",
        "        # 유사도에 따라 리뷰 정렬\n",
        "        related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "\n",
        "        # 상위 5개의 리뷰 추천\n",
        "        top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "\n",
        "        return top_reviews[['여행지', '해시태그']]\n",
        "\n",
        "\n",
        "    # 입력된 해시태그에 따라 관련 리뷰를 출력\n",
        "    recommended_reviews = get_recommendations_by_hashtags(selected_hashtag)\n",
        "\n",
        "    if not recommended_reviews.empty:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 상위 5개 여행지:\")\n",
        "        # index 제거\n",
        "        recommended_reviews.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # 해시태그 필터링\n",
        "        filtered_reviews = recommended_reviews[recommended_reviews['해시태그'].str.contains(selected_hashtag)]\n",
        "        print(filtered_reviews.to_string(index=False))\n",
        "    else:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 리뷰가 없습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF-UTm-f_PRv",
        "outputId": "3c6785d5-9a1e-4e46-f4af-d01a5b83d14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#도시 #자연 #역사 #바다 #산 #맛집 #풍경\n",
            "사용하려는 해시태그를 선택하세요: #도시\n",
            "#도시 해시태그에 관련된 상위 5개 여행지:\n",
            "여행지        해시태그\n",
            " 부산 #바다 #맛집 #도시\n",
            " 서울 #도시 #맛집 #역사\n",
            " 부산 #바다 #풍경 #도시\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data base 연결 시키면 쓸 부분(미완)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import sqlite3  # 데이터베이스 연동을 위한 라이브러리\n",
        "\n",
        "# 데이터베이스 연결\n",
        "conn = sqlite3.connect('travel_reviews.db')  # 데이터베이스 파일명은 'travel_reviews.db'로 가정\n",
        "\n",
        "# 데이터베이스에서 리뷰 데이터 가져오기\n",
        "reviews = pd.read_sql_query(\"SELECT * FROM reviews\", conn)\n",
        "available_hashtags = pd.read_sql_query(\"SELECT DISTINCT 해시태그 FROM reviews\", conn)['해시태그'].tolist()\n",
        "\n",
        "# 사용자에게 입력 받기\n",
        "print(\"(#봄여행#여름여행#가을여행#겨울여행#자연#도시여행#역사유적탐방#바다#산#계곡#음식여행#문화축제#미술#백패킹#스포츠여행#농촌여행#호캉스#뚜벅이#자차#쇼핑#tv프로소개)\")\n",
        "selected_hashtag = input(\"사용하려는 해시태그를 선택하세요: \")\n",
        "if selected_hashtag not in available_hashtags:\n",
        "    print(\"잘못된 해시태그입니다.\")\n",
        "else:\n",
        "    # 입력된 해시태그에 따라 관련 리뷰를 추천\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(reviews['해시태그'])\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    def get_recommendations_by_hashtags(input_hashtags, cosine_sim=cosine_sim):\n",
        "        input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "        sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "        related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "        top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "        return top_reviews[['여행지', '해시태그']]\n",
        "\n",
        "    recommended_reviews = get_recommendations_by_hashtags(selected_hashtag)\n",
        "\n",
        "    if not recommended_reviews.empty:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 상위 5개 여행지:\")\n",
        "        recommended_reviews.reset_index(drop=True, inplace=True)\n",
        "        filtered_reviews = recommended_reviews[recommended_reviews['해시태그'].str.contains(selected_hashtag)]\n",
        "        print(filtered_reviews.to_string(index=False))\n",
        "    else:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 리뷰가 없습니다.\")\n",
        "\n",
        "\n",
        "# 데이터베이스 연결 종료\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "EmmzNzzpAIAr",
        "outputId": "08333edf-14fd-4f76-aead-daa418a9f346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: reviews",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-178a17e3f582>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 데이터베이스에서 리뷰 데이터 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mavailable_hashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT DISTINCT 해시태그 FROM reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'해시태그'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[1;32m    396\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2079\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM reviews': no such table: reviews"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# GW 키 설정\n",
        "gw_key = \"NB11m43WRMwKCe9w96hjIHPHlCuulBqp%2FKn83jLJtIUw6zUXTUca8FNPYUwucbh7zKLV%2BrRk%2F0kfSI%2Ff4R5z%2FA%3D%3D\"\n",
        "\n",
        "# API 엔드포인트 및 요청 헤더 설정\n",
        "url = \"https://api.example.com/some_endpoint\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {gw_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# API 요청 보내기\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# API 응답 처리\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    # 결과를 처리하거나 활용\n",
        "else:\n",
        "    print(\"API 요청에 실패했습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ok_mQ03o5xyM",
        "outputId": "86d1a0ed-3154-43b3-830c-397c72d12a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5103bbb1572b>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    gw_key = NB11m43WRMwKCe9w96hjIHPHlCuulBqp%2FKn83jLJtIUw6zUXTUca8FNPYUwucbh7zKLV%2BrRk%2F0kfSI%2Ff4R5z%2FA%3D%3D\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#별점 반영한 부분\n",
        "\n",
        "# import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# 여행지와 리뷰 데이터 생성\n",
        "data = pd.DataFrame({\n",
        "    '여행지': ['서울', '부산', '제주', '강릉', '경주'],\n",
        "    '평균 별점': [4.5, 4.2, 4.8, 4.6, 4.0]\n",
        "})\n",
        "\n",
        "reviews = pd.DataFrame({\n",
        "    '여행지': ['서울'] * 5 + ['부산'] * 5 + ['제주'] * 5 + ['강릉'] * 5 + ['경주'] * 5,\n",
        "    '해시태그': [\n",
        "        ##서울 해쉬태그\n",
        "        '#도시 #맛집 #역사',\n",
        "        '#부자 #도시 #맛집',\n",
        "        '#빌딩 #풍경 #번화',\n",
        "        '#번화 #아름다운',\n",
        "        '#도시 #문화',\n",
        "        ##부산 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#바다 #풍경 #도시',\n",
        "        '#번화 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##제주 해쉬태그\n",
        "        '#바다 #맛집 #도시',\n",
        "        '#바다 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식 # 바다',\n",
        "        '#바다 #아름다운',\n",
        "        '#바다 #문화',\n",
        "        ##강릉 해쉬태그\n",
        "        '#산 #맛집 #도시',\n",
        "        '#산 #풍경 #맛집',\n",
        "        '#자연 #풍경 #휴식',\n",
        "        '#산 #아름다운',\n",
        "        '#산 #조용',\n",
        "        ##경주 해쉬태그\n",
        "        '#역사 #맛집 #휴식',\n",
        "        '#역사 #풍경 #맛집',\n",
        "        '#역사 #풍경 #휴식',\n",
        "        '#역사 #아름다운',\n",
        "        '#역사 #문화',\n",
        "    ],\n",
        "    '별점': [4.5, 4.8, 4.3, 4.6, 4.7,\n",
        "            4.2, 4.5, 4.4, 4.6, 4.3,\n",
        "            2.8, 3.0, 3.5, 4.0, 3.8,\n",
        "            4.6, 4.7, 4.5, 4.2, 4.4,\n",
        "            3.9, 4.1, 3.7, 4.0, 4.2]\n",
        "})\n",
        "\n",
        "# 사용 가능한 해시태그 목록\n",
        "available_hashtags = ['#도시', '#자연', '#역사', '#바다','#산', '#맛집','#풍경']\n",
        "\n",
        "# 사용자에게 입력 받기\n",
        "print(\"#도시 #자연 #역사 #바다 #산 #맛집 #풍경\")\n",
        "selected_hashtag = input(\"사용하려는 해시태그를 선택하세요: \")\n",
        "if selected_hashtag not in available_hashtags:\n",
        "    print(\"잘못된 해시태그입니다.\")\n",
        "else:\n",
        "    # 입력된 해시태그에 따라 관련 리뷰를 추천\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(reviews['해시태그'] + ' ' + reviews['별점'].astype(str))\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    def get_recommendations_by_hashtags(input_hashtags, cosine_sim=cosine_sim):\n",
        "        input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "        sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "        related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "        top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "        return top_reviews[['여행지', '해시태그', '별점']]\n",
        "\n",
        "    recommended_reviews = get_recommendations_by_hashtags(selected_hashtag)\n",
        "\n",
        "    if not recommended_reviews.empty:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 상위 5개 여행지:\")\n",
        "        recommended_reviews.reset_index(drop=True, inplace=True)\n",
        "        filtered_reviews = recommended_reviews[recommended_reviews['해시태그'].str.contains(selected_hashtag)]\n",
        "        print(filtered_reviews.to_string(index=False))\n",
        "    else:\n",
        "        print(f\"{selected_hashtag} 해시태그에 관련된 리뷰가 없습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgilaEGoAWo6",
        "outputId": "c4a60b21-392f-4b58-984e-d9e0d9f65c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#도시 #자연 #역사 #바다 #산 #맛집 #풍경\n",
            "사용하려는 해시태그를 선택하세요: #도시\n",
            "#도시 해시태그에 관련된 상위 5개 여행지:\n",
            "여행지        해시태그  별점\n",
            " 강릉  #산 #맛집 #도시 4.6\n",
            " 서울     #도시 #문화 4.7\n",
            " 부산 #바다 #맛집 #도시 4.2\n",
            " 제주 #바다 #맛집 #도시 2.8\n",
            " 부산 #바다 #풍경 #도시 4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import sqlite3\n",
        "\n",
        "# 데이터베이스 연결\n",
        "conn = sqlite3.connect('travel_reviews.db')  # 데이터베이스 파일명은 'travel_reviews.db'로 가정\n",
        "\n",
        "# 데이터베이스에서 리뷰 데이터 가져오기\n",
        "reviews = pd.read_sql_query(\"SELECT * FROM reviews\", conn)\n",
        "\n",
        "# API 요청 함수\n",
        "def get_api_data():\n",
        "    # API 요청에 필요한 매개변수 설정\n",
        "    params = {\n",
        "        'numOfRows': 10,\n",
        "        'pageNo': 1,\n",
        "        'MobileOS': 'ETC',\n",
        "        'MobileApp': 'AppTest',\n",
        "        '_type': 'json',\n",
        "        'listYN': 'Y',\n",
        "        'arrange': 'A',\n",
        "        'keyword': '강원',\n",
        "        'contentTypeId': 12,\n",
        "        'serviceKey': ''\n",
        "    }\n",
        "\n",
        "    # API 요청 URL 생성\n",
        "    base_url = 'NB11m43WRMwKCe9w96hjIHPHlCuulBqp%2FKn83jLJtIUw6zUXTUca8FNPYUwucbh7zKLV%2BrRk%2F0kfSI%2Ff4R5z%2FA%3D%3D'\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    # API 응답 확인\n",
        "    if response.status_code == 200:\n",
        "        # JSON 형식으로 응답 데이터 파싱\n",
        "        data = response.json()\n",
        "        return data\n",
        "    else:\n",
        "        print(\"API 요청에 실패하였습니다.\")\n",
        "        return None\n",
        "\n",
        "# API 데이터 받아오기\n",
        "api_data = get_api_data()\n",
        "\n",
        "if api_data is not None:\n",
        "    # API 데이터를 pandas DataFrame으로 변환\n",
        "    api_df = pd.DataFrame(api_data['items'])\n",
        "\n",
        "    # 여기에서 api_df를 활용하여 원하는 데이터 추출 및 처리\n",
        "\n",
        "    # 사용자에게 입력 받기\n",
        "    print(\"(#봄여행#여름여행#가을여행#겨울여행#자연#도시여행#역사유적탐방#바다#산#계곡#음식여행#문화축제#미술#백패킹#스포츠여행#농촌여행#호캉스#뚜벅이#자차#쇼핑#tv프로소개)\")\n",
        "    selected_hashtag = input(\"사용하려는 해시태그를 선택하세요: \")\n",
        "    if selected_hashtag not in api_df['해시태그'].tolist():\n",
        "        print(\"잘못된 해시태그입니다.\")\n",
        "    else:\n",
        "        # 입력된 해시태그에 따라 관련 리뷰를 추천\n",
        "        tfidf_vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = tfidf_vectorizer.fit_transform(reviews['해시태그'])\n",
        "        cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "        def get_recommendations_by_hashtags(input_hashtags, cosine_sim=cosine_sim):\n",
        "            input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "            sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "            related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "            top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "            return top_reviews[['여행지', '해시태그']]\n",
        "\n",
        "        recommended_reviews = get_recommendations_by_hashtags(selected_hashtag)\n",
        "\n",
        "        if not recommended_reviews.empty:\n",
        "            print(f\"{selected_hashtag} 해시태그에 관련된 상위 5개 여행지:\")\n",
        "            recommended_reviews.reset_index(drop=True, inplace=True)\n",
        "            filtered_reviews = recommended_reviews[recommended_reviews['해시태그'].str.contains(selected_hashtag)]\n",
        "            print(filtered_reviews.to_string(index=False))\n",
        "        else:\n",
        "            print(f\"{selected_hashtag} 해시태그에 관련된 리뷰가 없습니다.\")\n",
        "\n",
        "# 데이터베이스 연결 종료\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "3_ZSsBfQPIk-",
        "outputId": "b33bdace-e791-4eb0-a1c8-ff59f16ac9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: reviews",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2dbca67751bc>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 데이터베이스에서 리뷰 데이터 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# API 요청 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[1;32m    396\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2079\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM reviews': no such table: reviews"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yMouvgV1NQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install supabase-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KmzmftA21OPg",
        "outputId": "893ee4ff-6fb3-4285-de05-214ed296cf17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase-py\n",
            "  Downloading supabase_py-0.0.2-py3-none-any.whl (7.5 kB)\n",
            "Collecting gotrue==0.2.0 (from supabase-py)\n",
            "  Downloading gotrue-0.2.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting postgrest-py==0.4.0 (from supabase-py)\n",
            "  Downloading postgrest_py-0.4.0-py3-none-any.whl (6.0 kB)\n",
            "Collecting pytest<7,>=6 (from supabase-py)\n",
            "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting realtime-py<0.2.0,>=0.1.2 (from supabase-py)\n",
            "  Downloading realtime_py-0.1.3-py3-none-any.whl (8.1 kB)\n",
            "Collecting requests==2.25.1 (from supabase-py)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation<3.0.0,>=2.1.0 (from postgrest-py==0.4.0->supabase-py)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting httpx<0.17.0,>=0.16.1 (from postgrest-py==0.4.0->supabase-py)\n",
            "  Downloading httpx-0.16.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet<5,>=3.0.2 (from requests==2.25.1->supabase-py)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<3,>=2.5 (from requests==2.25.1->supabase-py)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests==2.25.1->supabase-py)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->supabase-py) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (1.3.0)\n",
            "Collecting py>=1.8.2 (from pytest<7,>=6->supabase-py)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (0.10.2)\n",
            "Collecting dataclasses<0.7,>=0.6 (from realtime-py<0.2.0,>=0.1.2->supabase-py)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from realtime-py<0.2.0,>=0.1.2->supabase-py) (2.8.2)\n",
            "Collecting websockets<10.0,>=9.1 (from realtime-py<0.2.0,>=0.1.2->supabase-py)\n",
            "  Downloading websockets-9.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py) (1.3.0)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.12.* (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py)\n",
            "  Downloading httpcore-0.12.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11==0.* (from httpcore==0.12.*->httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime-py<0.2.0,>=0.1.2->supabase-py) (1.16.0)\n",
            "Building wheels for collected packages: websockets\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-9.1-cp310-cp310-linux_x86_64.whl size=97278 sha256=6f6d5faed435c95f044a2e6ef81df9c5819af621a027b28969fc7fb633ed9b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/f7/4e/873eca27ecd6d7230caff265283a5a5112ad4cd1d945c022dd\n",
            "Successfully built websockets\n",
            "Installing collected packages: rfc3986, dataclasses, websockets, urllib3, py, idna, h11, gotrue, deprecation, chardet, requests, realtime-py, pytest, httpcore, httpx, postgrest-py, supabase-py\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.3\n",
            "    Uninstalling pytest-7.4.3:\n",
            "      Successfully uninstalled pytest-7.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.10.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.13.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.31 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 dataclasses-0.6 deprecation-2.1.0 gotrue-0.2.0 h11-0.14.0 httpcore-0.12.3 httpx-0.16.1 idna-2.10 postgrest-py-0.4.0 py-1.11.0 pytest-6.2.5 realtime-py-0.1.3 requests-2.25.1 rfc3986-1.5.0 supabase-py-0.0.2 urllib3-1.26.18 websockets-9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "dataclasses",
                  "idna",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xl_yP45RAmXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supabase import create_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "mh8eLD7M1Ror",
        "outputId": "adc0054a-3bcc-4eb1-da39-58ef4bc5199d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5e6ca80402f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msupabase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supabase'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Rcfh-t6VOJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# API 엔드포인트 URL 설정\n",
        "api_url = 'http://apis.data.go.kr/B551011/KorService1'\n",
        "\n",
        "# API에서 데이터 가져오기\n",
        "response = requests.get(api_url)\n",
        "\n",
        "try:\n",
        "    # API 응답을 JSON으로 파싱\n",
        "    data = response.json()\n",
        "\n",
        "    # 데이터를 데이터프레임으로 변환 (pandas DataFrame)\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # CSV 파일로 저장\n",
        "    csv_filename = 'api_data.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "\n",
        "    print(f'Data saved to {csv_filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "4iVmZlZleeYm",
        "outputId": "168ae9f3-c79f-4d20-feee-584668bc381c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-c9c9860afe46>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print(f'Data saved to {csv_filename}')\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o api_data.json \"http://apis.data.go.kr/B551011/KorService1\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8cWoBz-fPNJ",
        "outputId": "3d964c98-b6a3-439d-932b-1f9076a6bd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   682  100   682    0     0   1146      0 --:--:-- --:--:-- --:--:--  1148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# JSON 파일 읽기\n",
        "with open('api_data.json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# CSV 파일로 저장\n",
        "csv_filename = 'api_data.csv'\n",
        "with open(csv_filename, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # 헤더 작성\n",
        "    headers = data[0].keys()\n",
        "    csv_writer.writerow(headers)\n",
        "\n",
        "    # 데이터 작성\n",
        "    for item in data:\n",
        "        csv_writer.writerow(item.values())\n",
        "\n",
        "print(f'Data saved to {csv_filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "rJCVDVhmfV6S",
        "outputId": "25aca9e8-8b90-46ad-f6ae-28a7323c8cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-689934c65122>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# JSON 파일 읽기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'api_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# CSV 파일로 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supabase-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt0V78oT1iMo",
        "outputId": "ce47dcc4-f013-4f17-9a33-6488117167e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supabase-py in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: gotrue==0.2.0 in /usr/local/lib/python3.10/dist-packages (from supabase-py) (0.2.0)\n",
            "Requirement already satisfied: postgrest-py==0.4.0 in /usr/local/lib/python3.10/dist-packages (from supabase-py) (0.4.0)\n",
            "Requirement already satisfied: pytest<7,>=6 in /usr/local/lib/python3.10/dist-packages (from supabase-py) (6.2.5)\n",
            "Requirement already satisfied: realtime-py<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from supabase-py) (0.1.3)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.10/dist-packages (from supabase-py) (2.25.1)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from postgrest-py==0.4.0->supabase-py) (2.1.0)\n",
            "Requirement already satisfied: httpx<0.17.0,>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from postgrest-py==0.4.0->supabase-py) (0.16.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->supabase-py) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->supabase-py) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->supabase-py) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->supabase-py) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (1.3.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (1.11.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pytest<7,>=6->supabase-py) (0.10.2)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6 in /usr/local/lib/python3.10/dist-packages (from realtime-py<0.2.0,>=0.1.2->supabase-py) (0.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from realtime-py<0.2.0,>=0.1.2->supabase-py) (2.8.2)\n",
            "Requirement already satisfied: websockets<10.0,>=9.1 in /usr/local/lib/python3.10/dist-packages (from realtime-py<0.2.0,>=0.1.2->supabase-py) (9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py) (1.3.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.12.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py) (0.12.3)\n",
            "Requirement already satisfied: h11==0.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.12.*->httpx<0.17.0,>=0.16.1->postgrest-py==0.4.0->supabase-py) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime-py<0.2.0,>=0.1.2->supabase-py) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import supabase\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "n_E-fiE81oKC",
        "outputId": "2d2926cb-82e1-40c9-d5a8-974d48e1f7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2bc37afbae34>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msupabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supabase'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import createClient from supabase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "FJSMSWOzvel_",
        "outputId": "cd706625-6946-494f-bd2c-2666612c36c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-472af25b95b2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import createClient from supabase\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import sqlite3\n",
        "from rdflib import Graph\n",
        "\n",
        "# 데이터베이스 연결\n",
        "conn = sqlite3.connect('travel_reviews.db')  # 데이터베이스 파일명은 'travel_reviews.db'로 가정\n",
        "\n",
        "# 데이터베이스에서 리뷰 데이터 가져오기\n",
        "reviews = pd.read_sql_query(\"SELECT * FROM reviews\", conn)\n",
        "\n",
        "# RDF 그래프 생성\n",
        "g = Graph()\n",
        "# .nt 파일을 로드\n",
        "g.parse('visitkorea.nt', format='nt')\n",
        "\n",
        "# API 데이터 받아오기\n",
        "# 여기에서 API 데이터를 가져오는 부분을 RDF 데이터를 읽는 코드로 변경해야 합니다.\n",
        "\n",
        "# 사용자에게 입력 받기\n",
        "print(\"(#봄여행#여름여행#가을여행#겨울여행#자연#도시여행#역사유적탐방#바다#산#계곡#음식여행#문화축제#미술#백패킹#스포츠여행#농촌여행#호캉스#뚜벅이#자차#쇼핑#tv프로소개)\")\n",
        "selected_hashtag = input(\"사용하려는 해시태그를 선택하세요: \")\n",
        "\n",
        "# 여행지 정보 추출 (예시: 관광명소와 관련 정보 추출)\n",
        "query = \"\"\"\n",
        "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "    SELECT ?place ?name ?description\n",
        "    WHERE {\n",
        "        ?place a <http://example.org/ontology/TravelDestination> ;\n",
        "               <http://example.org/ontology/name> ?name ;\n",
        "               <http://example.org/ontology/description> ?description .\n",
        "    }\n",
        "\"\"\"\n",
        "results = g.query(query)\n",
        "\n",
        "places_data = []\n",
        "for result in results:\n",
        "    place_data = {\n",
        "        'place': str(result.place),\n",
        "        'name': str(result.name),\n",
        "        'description': str(result.description),\n",
        "    }\n",
        "    places_data.append(place_data)\n",
        "\n",
        "# 입력된 해시태그에 따라 관련 리뷰를 추천\n",
        "input_hashtags = selected_hashtag  # 사용자 입력을 활용\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews['해시태그'])\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "def get_recommendations_by_hashtags(input_hashtags, cosine_sim=cosine_sim):\n",
        "    input_vector = tfidf_vectorizer.transform([input_hashtags])\n",
        "    sim_scores = linear_kernel(input_vector, tfidf_matrix).flatten()\n",
        "    related_reviews_indices = sim_scores.argsort()[::-1]\n",
        "    top_reviews = reviews.iloc[related_reviews_indices[:5]]\n",
        "    return top_reviews[['여행지', '해시태그']]\n",
        "\n",
        "recommended_reviews = get_recommendations_by_hashtags(input_hashtags)\n",
        "\n",
        "if not recommended_reviews.empty:\n",
        "    print(f\"{selected_hashtag} 해시태그에 관련된 상위 5개 여행지:\")\n",
        "    recommended_reviews.reset_index(drop=True, inplace=True)\n",
        "    filtered_reviews = recommended_reviews[recommended_reviews['해시태그'].str.contains(selected_hashtag)]\n",
        "    print(filtered_reviews.to_string(index=False))\n",
        "else:\n",
        "    print(f\"{selected_hashtag} 해시태그에 관련된 리뷰가 없습니다.\")\n",
        "\n",
        "# 데이터베이스 연결 종료\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "EdRNt20cvstL",
        "outputId": "453d4232-7243-4ae7-f8b9-550303c6617f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: reviews",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7e922fe39f15>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 데이터베이스에서 리뷰 데이터 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# RDF 그래프 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[1;32m    396\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2079\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM reviews': no such table: reviews"
          ]
        }
      ]
    }
  ]
}